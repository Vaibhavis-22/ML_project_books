{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3593167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d451c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5590154",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the required sql functions for the further processing\n",
    "from pyspark.sql import functions\n",
    "from pyspark.sql.functions import col, trim, lower, regexp_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "614cd002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/07 12:29:05 WARN Utils: Your hostname, vaibhavi-HP-Laptop-15-fd0xxx resolves to a loopback address: 127.0.1.1; using 192.168.1.9 instead (on interface wlo1)\n",
      "25/07/07 12:29:05 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/07 12:29:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"BookRecommendEDA\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57b33869",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: string (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- Price: string (nullable = true)\n",
      " |-- User_id: string (nullable = true)\n",
      " |-- profileName: string (nullable = true)\n",
      " |-- review/helpfulness: string (nullable = true)\n",
      " |-- review/score: string (nullable = true)\n",
      " |-- review/time: string (nullable = true)\n",
      " |-- review/summary: string (nullable = true)\n",
      " |-- review/text: string (nullable = true)\n",
      "\n",
      "+----------+--------------------+-----+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
      "|        Id|               Title|Price|       User_id|         profileName|review/helpfulness|review/score|review/time|      review/summary|         review/text|\n",
      "+----------+--------------------+-----+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
      "|1882931173|Its Only Art If I...| NULL| AVCGYZL8FQQTD|\"Jim of Oz \"\"jim-...|               7/7|         4.0|  940636800|Nice collection o...|This is only for ...|\n",
      "|0826414346|Dr. Seuss: Americ...| NULL|A30TK6U7DNS82R|       Kevin Killian|             10/10|         5.0| 1095724800|   Really Enjoyed It|I don't care much...|\n",
      "|0826414346|Dr. Seuss: Americ...| NULL|A3UH4UZ4RSVO82|        John Granger|             10/11|         5.0| 1078790400|Essential for eve...|\"If people become...|\n",
      "|0826414346|Dr. Seuss: Americ...| NULL|A2MVUWT453QH61|\"Roy E. Perry \"\"a...|               7/7|         4.0| 1090713600|Phlip Nel gives s...|Theodore Seuss Ge...|\n",
      "|0826414346|Dr. Seuss: Americ...| NULL|A22X4XUPKF66MR|\"D. H. Richards \"...|               3/3|         4.0| 1107993600|Good academic ove...|\"Philip Nel - Dr....|\n",
      "+----------+--------------------+-----+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_reviews = spark.read.csv(\"/home/vaibhavi/spark-ml-venv/ml_project/data/Books_rating.csv\", header=True, inferSchema=True)\n",
    "df_reviews.printSchema()\n",
    "df_reviews.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e484e10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Title: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- image: string (nullable = true)\n",
      " |-- previewLink: string (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- publishedDate: string (nullable = true)\n",
      " |-- infoLink: string (nullable = true)\n",
      " |-- categories: string (nullable = true)\n",
      " |-- ratingsCount: string (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+--------------------+--------------------+------------+\n",
      "|               Title|         description|             authors|               image|         previewLink|           publisher| publishedDate|            infoLink|          categories|ratingsCount|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+--------------------+--------------------+------------+\n",
      "|Its Only Art If I...|                NULL|    ['Julie Strain']|http://books.goog...|http://books.goog...|                NULL|          1996|http://books.goog...|['Comics & Graphi...|        NULL|\n",
      "|Dr. Seuss: Americ...|\"Philip Nel takes...| like that of Lew...| has changed lang...| giving us new wo...| inspiring artist...|['Philip Nel']|http://books.goog...|http://books.goog...|   A&C Black|\n",
      "|Wonderful Worship...|This resource inc...|    ['David R. Ray']|http://books.goog...|http://books.goog...|                NULL|          2000|http://books.goog...|        ['Religion']|        NULL|\n",
      "|Whispers of the W...|Julia Thomas find...| ['Veronica Haddon']|http://books.goog...|http://books.goog...|           iUniverse|       2005-02|http://books.goog...|         ['Fiction']|        NULL|\n",
      "|Nation Dance: Rel...|                NULL|     ['Edward Long']|                NULL|http://books.goog...|                NULL|    2003-03-01|http://books.goog...|                NULL|        NULL|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+--------------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_books = spark.read.csv(\"/home/vaibhavi/spark-ml-venv/ml_project/data/books_data.csv\", header=True, inferSchema=True)\n",
    "df_books.printSchema()\n",
    "df_books.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22c0506",
   "metadata": {},
   "source": [
    "actual Schema : Title,description,authors,image,previewLink,publisher,publishedDate,infoLink,categories,ratingsCount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c1b8a5",
   "metadata": {},
   "source": [
    "#required columns from both the tables:\n",
    "- title, userId, review_score, tb2 - title, authors ,publisher, categories,description, ratingsCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dda28f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting required columns from books dataframe\n",
    "df_required1 = df_books.select(\"Title\",\"description\",\"authors\",\"publisher\", \"categories\",\"ratingsCount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0e4db2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:=================================================>       (19 + 3) / 22]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|               Title|review_count|\n",
      "+--------------------+------------+\n",
      "|Isaac Asimov: Mas...|           2|\n",
      "|     White Rock Ways|           1|\n",
      "|The Face of the T...|           1|\n",
      "|Your Signature Li...|           4|\n",
      "|     Iridescent Soul|           8|\n",
      "|L'Alchimiste (Cof...|          13|\n",
      "|  The Book of Garlic|           1|\n",
      "|A Jesse Stuart Ha...|           1|\n",
      "|Raymond Chandler:...|          15|\n",
      "|      Badenheim 1939|          26|\n",
      "|        Pagan Babies|          16|\n",
      "|The Self and its ...|           3|\n",
      "|The Educated Chil...|          37|\n",
      "|Future Perfect - ...|           2|\n",
      "|The cornet of hor...|          18|\n",
      "|Basic Arabic Work...|           7|\n",
      "|Organizational Th...|           5|\n",
      "|Oz and Beyond: Th...|           1|\n",
      "|Fundamentals of I...|           3|\n",
      "|We Love Baseball!...|           2|\n",
      "+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "review_counts = df_reviews.groupBy(\"Title\").count().withColumnRenamed(\"count\", \"review_count\")\n",
    "\n",
    "review_counts.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d75e3d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Title: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- categories: string (nullable = true)\n",
      " |-- ratingsCount: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_required1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6243f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Title: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- categories: string (nullable = true)\n",
      " |-- ratingsCount: string (nullable = true)\n",
      " |-- review_count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_required1 = df_required1.join(review_counts , on = [\"Title\"] ,how = 'left')\n",
    "\n",
    "df_required1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c06f753a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212404"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_required1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e3a4942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: string (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- User_id: string (nullable = true)\n",
      " |-- review/score: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_reviews= df_reviews.drop(\"review/helpfulness\",\"review/time\",\"review/summary\",\"review/text\",\"Price\",\"profileName\")\n",
    "df_reviews.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "33945a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_als = df_reviews.select(\"Id\",\"User_id\",\"review/score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "056d2b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3000000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_als.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ce7d2cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: string (nullable = true)\n",
      " |-- User_id: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_als = df_als.withColumnRenamed(\"review/score\",\"rating\")\n",
    "df_als.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd05d82e",
   "metadata": {},
   "source": [
    "there are several duplicate values of same user giving different ratings to the same book, we will be averaging their ratings to have proper data, as als (collaborative filtering) requires distinct user_id, id and the rating triplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "79a0bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are several duplicate values in the ratings column \n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "df_als = df_als.groupBy(\"User_id\", \"Id\").agg(avg(\"rating\").alias(\"rating\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9d899fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "96862"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_als.filter(\n",
    "    col(\"User_id\").isNull() | col(\"Id\").isNull() | col(\"rating\").isNull()\n",
    ").count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d88ba542",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_als = df_als.dropna(subset=[\"User_id\", \"Id\", \"rating\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a57fb031",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2380346"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_als.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "76edcdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#as we did with sentiment, storing the data in batches\n",
    "num_batches = 10\n",
    "\n",
    "# splitting into batches\n",
    "batches = df_als.randomSplit([1.0] * num_batches, seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bffa0a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving batch 1 to Parquet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/07 13:47:18 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "25/07/07 13:47:18 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:47:18 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:47:18 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:47:18 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 60.98% for 12 writers\n",
      "25/07/07 13:47:18 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:47:18 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:47:18 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:47:18 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving batch 2 to Parquet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/07 13:47:23 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "25/07/07 13:47:23 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:47:23 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:47:23 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:47:23 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 60.98% for 12 writers\n",
      "25/07/07 13:47:23 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:47:23 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:47:23 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:47:23 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving batch 3 to Parquet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/07 13:47:28 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "25/07/07 13:47:28 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:47:28 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:47:28 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:47:28 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 60.98% for 12 writers\n",
      "25/07/07 13:47:28 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:47:28 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:47:28 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:47:28 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving batch 4 to Parquet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/07 13:47:33 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "25/07/07 13:47:33 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:47:33 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:47:33 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:47:33 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 60.98% for 12 writers\n",
      "25/07/07 13:47:33 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:47:33 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:47:33 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:47:33 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving batch 5 to Parquet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/07 13:47:38 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "25/07/07 13:47:38 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:47:38 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:47:38 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:47:38 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 60.98% for 12 writers\n",
      "25/07/07 13:47:38 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:47:38 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:47:38 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:47:38 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving batch 6 to Parquet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/07 13:47:43 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "25/07/07 13:47:43 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:47:43 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:47:43 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:47:43 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 60.98% for 12 writers\n",
      "25/07/07 13:47:43 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:47:43 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:47:43 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:47:43 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving batch 7 to Parquet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/07 13:47:50 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "25/07/07 13:47:50 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:47:50 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:47:50 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:47:50 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 60.98% for 12 writers\n",
      "25/07/07 13:47:51 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:47:51 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:47:51 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:47:51 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving batch 8 to Parquet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/07 13:47:58 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "25/07/07 13:47:58 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:47:58 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:47:58 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:47:58 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:47:58 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:47:58 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "25/07/07 13:47:58 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:47:58 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving batch 9 to Parquet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/07 13:48:05 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "25/07/07 13:48:05 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:48:05 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:48:05 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:48:05 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 60.98% for 12 writers\n",
      "25/07/07 13:48:05 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:48:05 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:48:05 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:48:05 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving batch 10 to Parquet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/07 13:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "25/07/07 13:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 60.98% for 12 writers\n",
      "25/07/07 13:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/07 14:12:59 WARN TransportChannelHandler: Exception in connection from /192.168.1.9:34823\n",
      "java.io.IOException: Connection timed out\n",
      "\tat sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)\n",
      "\tat sun.nio.ch.IOUtil.read(IOUtil.java:192)\n",
      "\tat sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:254)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    }
   ],
   "source": [
    "# Save each batch as a separate Parquet file\n",
    "for i, batch in enumerate(batches):\n",
    "    print(f\"Saving batch {i+1} to Parquet...\")\n",
    "    batch.write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .parquet(f\"output/als/als_parquet_batch_{i+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347e0929",
   "metadata": {},
   "source": [
    "##### now lets create EDA content-based required data  and check for the data in it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a177c93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+----------+------------+\n",
      "|column      |dtype |null_count|null_percent|\n",
      "+------------+------+----------+------------+\n",
      "|Title       |string|1         |0.0         |\n",
      "|description |string|68357     |32.18       |\n",
      "|authors     |string|31251     |14.71       |\n",
      "|publisher   |string|73130     |34.43       |\n",
      "|categories  |string|40524     |19.08       |\n",
      "|ratingsCount|string|148552    |69.94       |\n",
      "|review_count|bigint|1         |0.0         |\n",
      "+------------+------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count, when, lit\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Total number of rows in the DataFrame\n",
    "total_rows = df_required1.count()\n",
    "\n",
    "\n",
    "schema_info = [(f.name, f.dataType.simpleString()) for f in df_required1.schema.fields]\n",
    "\n",
    "null_counts = df_required1.select([\n",
    "    count(when(col(c).isNull(), c)).alias(c) for c, _ in schema_info\n",
    "]).collect()[0].asDict()\n",
    "\n",
    "# Create Spark DataFrame for summary\n",
    "summary_data = [\n",
    "    (col_name, dtype, null_counts[col_name], round(100 * null_counts[col_name] / total_rows, 2))\n",
    "    for col_name, dtype in schema_info\n",
    "]\n",
    "\n",
    "\n",
    "summary_df = spark.createDataFrame(\n",
    "    summary_data,\n",
    "    [\"column\", \"dtype\", \"null_count\", \"null_percent\"]\n",
    ")\n",
    "\n",
    "summary_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "12fcadcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Title: string (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- categories: string (nullable = true)\n",
      " |-- review_count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from the summary, ratings count is filled with lot of null,values, we will be dropping it, given that description is a text field \n",
    "# 32% empty would unncessary add overhead to the model for text processing ,so dropping description and publisher description as well\n",
    "\n",
    "df_required1 = df_required1.drop(\"ratingsCount\",\"description\",\"publisher\")\n",
    "\n",
    "df_required1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "da0d0802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212404"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_required1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "12718fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# Clean nulls\n",
    "df_cleaned = df_required1 \\\n",
    "    .filter(col(\"Title\").isNotNull() & col(\"review_count\").isNotNull()) \\\n",
    "    .withColumn(\"authors\", when(col(\"authors\").isNull(), \"Unknown\").otherwise(col(\"authors\"))) \\\n",
    "    .withColumn(\"categories\", when(col(\"categories\").isNull(), \"Unknown\").otherwise(col(\"categories\")))\n",
    "\n",
    "\n",
    "# Final selected columns\n",
    "df_content_final = df_cleaned.select(\"Title\", \"authors\", \"categories\", \"review_count\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0632bc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#as the data size is small, we will be only saving itno 2 batches\n",
    "\n",
    "total_rows = df_content_final.count()\n",
    "batch_size = total_rows // 2\n",
    "batches = [\n",
    "    df_content_final.limit(batch_size),\n",
    "    df_content_final.subtract(df_content_final.limit(batch_size))\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "61a0ff96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving content batch 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving content batch 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#storing in parquest agian\n",
    "\n",
    "for i, batch in enumerate(batches):\n",
    "    print(f\"Saving content batch {i + 1}...\")\n",
    "    batch.write.mode(\"overwrite\").parquet(f\"output/content/content_batch_{i + 1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b7db8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-project-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
