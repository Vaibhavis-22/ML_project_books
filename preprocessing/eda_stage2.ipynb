{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3593167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d451c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5590154",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the required sql functions for the further processing\n",
    "from pyspark.sql import functions\n",
    "from pyspark.sql.functions import col, trim, lower, regexp_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "614cd002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/21 10:23:00 WARN Utils: Your hostname, vaibhavi-HP-Laptop-15-fd0xxx resolves to a loopback address: 127.0.1.1; using 172.18.4.62 instead (on interface wlo1)\n",
      "25/07/21 10:23:00 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/21 10:23:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/07/21 10:23:02 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"BookRecommendEDA\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57b33869",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: string (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- Price: string (nullable = true)\n",
      " |-- User_id: string (nullable = true)\n",
      " |-- profileName: string (nullable = true)\n",
      " |-- review/helpfulness: string (nullable = true)\n",
      " |-- review/score: string (nullable = true)\n",
      " |-- review/time: string (nullable = true)\n",
      " |-- review/summary: string (nullable = true)\n",
      " |-- review/text: string (nullable = true)\n",
      "\n",
      "+----------+--------------------+-----+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
      "|        Id|               Title|Price|       User_id|         profileName|review/helpfulness|review/score|review/time|      review/summary|         review/text|\n",
      "+----------+--------------------+-----+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
      "|1882931173|Its Only Art If I...| NULL| AVCGYZL8FQQTD|\"Jim of Oz \"\"jim-...|               7/7|         4.0|  940636800|Nice collection o...|This is only for ...|\n",
      "|0826414346|Dr. Seuss: Americ...| NULL|A30TK6U7DNS82R|       Kevin Killian|             10/10|         5.0| 1095724800|   Really Enjoyed It|I don't care much...|\n",
      "|0826414346|Dr. Seuss: Americ...| NULL|A3UH4UZ4RSVO82|        John Granger|             10/11|         5.0| 1078790400|Essential for eve...|\"If people become...|\n",
      "|0826414346|Dr. Seuss: Americ...| NULL|A2MVUWT453QH61|\"Roy E. Perry \"\"a...|               7/7|         4.0| 1090713600|Phlip Nel gives s...|Theodore Seuss Ge...|\n",
      "|0826414346|Dr. Seuss: Americ...| NULL|A22X4XUPKF66MR|\"D. H. Richards \"...|               3/3|         4.0| 1107993600|Good academic ove...|\"Philip Nel - Dr....|\n",
      "+----------+--------------------+-----+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_reviews = spark.read.csv(\"/home/vaibhavi/spark-ml-venv/ml_project/data/Books_rating.csv\", header=True, inferSchema=True)\n",
    "df_reviews.printSchema()\n",
    "df_reviews.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e484e10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Title: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- image: string (nullable = true)\n",
      " |-- previewLink: string (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- publishedDate: string (nullable = true)\n",
      " |-- infoLink: string (nullable = true)\n",
      " |-- categories: string (nullable = true)\n",
      " |-- ratingsCount: string (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+--------------------+--------------------+------------+\n",
      "|               Title|         description|             authors|               image|         previewLink|           publisher| publishedDate|            infoLink|          categories|ratingsCount|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+--------------------+--------------------+------------+\n",
      "|Its Only Art If I...|                NULL|    ['Julie Strain']|http://books.goog...|http://books.goog...|                NULL|          1996|http://books.goog...|['Comics & Graphi...|        NULL|\n",
      "|Dr. Seuss: Americ...|\"Philip Nel takes...| like that of Lew...| has changed lang...| giving us new wo...| inspiring artist...|['Philip Nel']|http://books.goog...|http://books.goog...|   A&C Black|\n",
      "|Wonderful Worship...|This resource inc...|    ['David R. Ray']|http://books.goog...|http://books.goog...|                NULL|          2000|http://books.goog...|        ['Religion']|        NULL|\n",
      "|Whispers of the W...|Julia Thomas find...| ['Veronica Haddon']|http://books.goog...|http://books.goog...|           iUniverse|       2005-02|http://books.goog...|         ['Fiction']|        NULL|\n",
      "|Nation Dance: Rel...|                NULL|     ['Edward Long']|                NULL|http://books.goog...|                NULL|    2003-03-01|http://books.goog...|                NULL|        NULL|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+--------------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_books = spark.read.csv(\"/home/vaibhavi/spark-ml-venv/ml_project/data/books_data.csv\", header=True, inferSchema=True)\n",
    "df_books.printSchema()\n",
    "df_books.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22c0506",
   "metadata": {},
   "source": [
    "actual Schema : Title,description,authors,image,previewLink,publisher,publishedDate,infoLink,categories,ratingsCount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c1b8a5",
   "metadata": {},
   "source": [
    "#required columns from both the tables:\n",
    "- title, userId, review_score, tb2 - title, authors ,publisher, categories,description, ratingsCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dda28f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting required columns from books dataframe\n",
    "df_required1 = df_books.select(\"Title\",\"description\",\"authors\",\"publisher\", \"categories\",\"ratingsCount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0e4db2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:======================================>                  (15 + 7) / 22]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|               Title|review_count|\n",
      "+--------------------+------------+\n",
      "|Isaac Asimov: Mas...|           2|\n",
      "|     White Rock Ways|           1|\n",
      "|The Face of the T...|           1|\n",
      "|Your Signature Li...|           4|\n",
      "|     Iridescent Soul|           8|\n",
      "|L'Alchimiste (Cof...|          13|\n",
      "|  The Book of Garlic|           1|\n",
      "|A Jesse Stuart Ha...|           1|\n",
      "|Raymond Chandler:...|          15|\n",
      "|      Badenheim 1939|          26|\n",
      "|        Pagan Babies|          16|\n",
      "|The Self and its ...|           3|\n",
      "|The Educated Chil...|          37|\n",
      "|Future Perfect - ...|           2|\n",
      "|The cornet of hor...|          18|\n",
      "|Basic Arabic Work...|           7|\n",
      "|Organizational Th...|           5|\n",
      "|Oz and Beyond: Th...|           1|\n",
      "|Fundamentals of I...|           3|\n",
      "|We Love Baseball!...|           2|\n",
      "+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "review_counts = df_reviews.groupBy(\"Title\").count().withColumnRenamed(\"count\", \"review_count\")\n",
    "\n",
    "review_counts.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d75e3d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Title: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- categories: string (nullable = true)\n",
      " |-- ratingsCount: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_required1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6243f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Title: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- categories: string (nullable = true)\n",
      " |-- ratingsCount: string (nullable = true)\n",
      " |-- review_count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_required1 = df_required1.join(review_counts , on = [\"Title\"] ,how = 'left')\n",
    "\n",
    "df_required1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c06f753a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212404"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_required1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e3a4942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: string (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- User_id: string (nullable = true)\n",
      " |-- review/score: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_reviews= df_reviews.drop(\"review/helpfulness\",\"review/time\",\"review/summary\",\"review/text\",\"Price\",\"profileName\")\n",
    "df_reviews.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "33945a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_als = df_reviews.select(\"Id\",\"User_id\",\"review/score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "056d2b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3000000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_als.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ce7d2cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: string (nullable = true)\n",
      " |-- User_id: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_als = df_als.withColumnRenamed(\"review/score\",\"rating\")\n",
    "df_als.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd05d82e",
   "metadata": {},
   "source": [
    "there are several duplicate values of same user giving different ratings to the same book, we will be averaging their ratings to have proper data, as als (collaborative filtering) requires distinct user_id, id and the rating triplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "79a0bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are several duplicate values in the ratings column \n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "df_als = df_als.groupBy(\"User_id\", \"Id\").agg(avg(\"rating\").alias(\"rating\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9d899fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "96862"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_als.filter(\n",
    "    col(\"User_id\").isNull() | col(\"Id\").isNull() | col(\"rating\").isNull()\n",
    ").count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d88ba542",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_als = df_als.dropna(subset=[\"User_id\", \"Id\", \"rating\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a57fb031",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2380346"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_als.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "76edcdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#as we did with sentiment, storing the data in batches\n",
    "num_batches = 10\n",
    "\n",
    "# splitting into batches\n",
    "batches = df_als.randomSplit([1.0] * num_batches, seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bffa0a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving batch 1 to Parquet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/07 13:47:18 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "25/07/07 13:47:18 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:47:18 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:47:18 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:47:18 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 60.98% for 12 writers\n",
      "25/07/07 13:47:18 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:47:18 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:47:18 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:47:18 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving batch 2 to Parquet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/07 13:47:23 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "25/07/07 13:47:23 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:47:23 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:47:23 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:47:23 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 60.98% for 12 writers\n",
      "25/07/07 13:47:23 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:47:23 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:47:23 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:47:23 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving batch 3 to Parquet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/07 13:47:28 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "25/07/07 13:47:28 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:47:28 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:47:28 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:47:28 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 60.98% for 12 writers\n",
      "25/07/07 13:47:28 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:47:28 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:47:28 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:47:28 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving batch 4 to Parquet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/07 13:47:33 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "25/07/07 13:47:33 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:47:33 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:47:33 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:47:33 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 60.98% for 12 writers\n",
      "25/07/07 13:47:33 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:47:33 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:47:33 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:47:33 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving batch 5 to Parquet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/07 13:47:38 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "25/07/07 13:47:38 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:47:38 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:47:38 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:47:38 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 60.98% for 12 writers\n",
      "25/07/07 13:47:38 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:47:38 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:47:38 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:47:38 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving batch 6 to Parquet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/07 13:47:43 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "25/07/07 13:47:43 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:47:43 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:47:43 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:47:43 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 60.98% for 12 writers\n",
      "25/07/07 13:47:43 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:47:43 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:47:43 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:47:43 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving batch 7 to Parquet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/07 13:47:50 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "25/07/07 13:47:50 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:47:50 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:47:50 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:47:50 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 60.98% for 12 writers\n",
      "25/07/07 13:47:51 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:47:51 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:47:51 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:47:51 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving batch 8 to Parquet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/07 13:47:58 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "25/07/07 13:47:58 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:47:58 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:47:58 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:47:58 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:47:58 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:47:58 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "25/07/07 13:47:58 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:47:58 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving batch 9 to Parquet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/07 13:48:05 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "25/07/07 13:48:05 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:48:05 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:48:05 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:48:05 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 60.98% for 12 writers\n",
      "25/07/07 13:48:05 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:48:05 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:48:05 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:48:05 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving batch 10 to Parquet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/07 13:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "25/07/07 13:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 60.98% for 12 writers\n",
      "25/07/07 13:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 66.53% for 11 writers\n",
      "25/07/07 13:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 73.18% for 10 writers\n",
      "25/07/07 13:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 81.31% for 9 writers\n",
      "25/07/07 13:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (982,201,127 bytes) of heap memory\n",
      "Scaling row group sizes to 91.47% for 8 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/07 14:12:59 WARN TransportChannelHandler: Exception in connection from /192.168.1.9:34823\n",
      "java.io.IOException: Connection timed out\n",
      "\tat sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)\n",
      "\tat sun.nio.ch.IOUtil.read(IOUtil.java:192)\n",
      "\tat sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:254)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    }
   ],
   "source": [
    "# Save each batch as a separate Parquet file\n",
    "for i, batch in enumerate(batches):\n",
    "    print(f\"Saving batch {i+1} to Parquet...\")\n",
    "    batch.write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .parquet(f\"output/als/als_parquet_batch_{i+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347e0929",
   "metadata": {},
   "source": [
    "##### now lets create EDA content-based required data  and check for the data in it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a177c93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+----------+------------+\n",
      "|column      |dtype |null_count|null_percent|\n",
      "+------------+------+----------+------------+\n",
      "|Title       |string|1         |0.0         |\n",
      "|description |string|68357     |32.18       |\n",
      "|authors     |string|31251     |14.71       |\n",
      "|publisher   |string|73130     |34.43       |\n",
      "|categories  |string|40524     |19.08       |\n",
      "|ratingsCount|string|148552    |69.94       |\n",
      "|review_count|bigint|1         |0.0         |\n",
      "+------------+------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count, when, lit\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Total number of rows in the DataFrame\n",
    "total_rows = df_required1.count()\n",
    "\n",
    "\n",
    "schema_info = [(f.name, f.dataType.simpleString()) for f in df_required1.schema.fields]\n",
    "\n",
    "null_counts = df_required1.select([\n",
    "    count(when(col(c).isNull(), c)).alias(c) for c, _ in schema_info\n",
    "]).collect()[0].asDict()\n",
    "\n",
    "# Create Spark DataFrame for summary\n",
    "summary_data = [\n",
    "    (col_name, dtype, null_counts[col_name], round(100 * null_counts[col_name] / total_rows, 2))\n",
    "    for col_name, dtype in schema_info\n",
    "]\n",
    "\n",
    "\n",
    "summary_df = spark.createDataFrame(\n",
    "    summary_data,\n",
    "    [\"column\", \"dtype\", \"null_count\", \"null_percent\"]\n",
    ")\n",
    "\n",
    "summary_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12fcadcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Title: string (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- categories: string (nullable = true)\n",
      " |-- review_count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from the summary, ratings count is filled with lot of null,values, we will be dropping it, given that description is a text field \n",
    "# 32% empty would unncessary add overhead to the model for text processing ,so dropping description and publisher description as well\n",
    "\n",
    "df_required1 = df_required1.drop(\"ratingsCount\",\"description\",\"publisher\")\n",
    "\n",
    "df_required1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da0d0802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212404"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_required1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41726c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(Title='11,000 Years Lost', authors=\"['Peni R. Griffin']\", categories=\"['Juvenile Fiction']\", review_count=7),\n",
       " Row(Title='24 QUILTED GEMS: Sparkling Traditional and Original Projects', authors=\"['Gai Perry']\", categories=\"['Crafts & Hobbies']\", review_count=1),\n",
       " Row(Title='A book of remarkable criminals', authors=\"['Henry Brodribb Irving']\", categories=\"['Crime']\", review_count=12),\n",
       " Row(Title='ANPAO: AN AMERICAN INDIAN ODYSSEY', authors=\"['Jamake Highwater']\", categories=\"['Juvenile Nonfiction']\", review_count=16),\n",
       " Row(Title='Amanda Pig on Her Own', authors=None, categories=None, review_count=4),\n",
       " Row(Title='Applied Multivariate Statistics for the Social Sciences, Fifth Edition', authors=\"['James P. Stevens']\", categories=\"['Education']\", review_count=1),\n",
       " Row(Title='Are We Having Fun Yet?: The 16 Secrets of Happy Parenting', authors=\"['Kay Willis', 'Maryann Bucknum Brinley']\", categories=\"['Family & Relationships']\", review_count=9),\n",
       " Row(Title='BOOK OF COMMON PRAYER', authors=\"['Oxford University Press']\", categories=\"['Religion']\", review_count=2),\n",
       " Row(Title='Beverly Clark Showers', authors=\"['Beverly Clark']\", categories=None, review_count=1),\n",
       " Row(Title=\"Building Bridge: New, Quick, & Easy Way to Learn America's Favorite Card Game\", authors=None, categories=None, review_count=2),\n",
       " Row(Title='COP The Truth Behind the Badge', authors=\"['Adam Davis']\", categories=\"['Religion']\", review_count=8),\n",
       " Row(Title='Cambridge Companion to Verdi', authors=\"['Xiaoxia Wei']\", categories=\"['Music']\", review_count=1),\n",
       " Row(Title=\"China's Participation in the IMF, the World Bank, and GATT: Toward a Global Economic Order\", authors=None, categories=None, review_count=1),\n",
       " Row(Title='Choctaws at the Crossroads: The Political Economy of Class and Culture in the Oklahoma Timber Region', authors=\"['Sandra Faiman-Silva']\", categories=\"['Social Science']\", review_count=3),\n",
       " Row(Title='Christmas With Southern Living 1997', authors=\"['Rebecca Brennan', 'Adrienne E. Short', 'Julie Fisher']\", categories=\"['Cooking']\", review_count=2),\n",
       " Row(Title='Come Ninevah, Come Tyre: The Presidency of Edward M. Jason', authors=\"['Allen Drury']\", categories=\"['Fiction']\", review_count=1),\n",
       " Row(Title='Cow:', authors=\"['Dirk Van Loon']\", categories=\"['Technology & Engineering']\", review_count=5),\n",
       " Row(Title='Cry Havoc', authors=\"['Simon Mann']\", categories=\"['Biography & Autobiography']\", review_count=4),\n",
       " Row(Title='Cue the Dead Guy: A Polly Deacon Mystery', authors=None, categories=None, review_count=3),\n",
       " Row(Title='Dr. Seuss: American Icon', authors=' like that of Lewis Carroll and Edward Lear', categories='http://books.google.nl/books?id=IjvHQsCn_pgC&printsec=frontcover&dq=Dr.+Seuss:+American+Icon&hl=&cd=1&source=gbs_api', review_count=9),\n",
       " Row(Title=\"Dragon's Breath (Tales of the Frog Princess)\", authors=\"['E. D. Baker']\", categories=\"['Juvenile Fiction']\", review_count=11),\n",
       " Row(Title='Effective Authorware for Windows Versions 3.0 and 3.5', authors=\"['Daniel P. Weichart']\", categories=\"['Computers']\", review_count=1),\n",
       " Row(Title='Essential Daredevil, Vol. 3 (Marvel Essentials)', authors=None, categories=None, review_count=3),\n",
       " Row(Title=\"Everlasting Fire: Cowokoci's Legacy In The Seminole Struggle Against Western Expansion\", authors=\"['John Elder']\", categories=\"['Social Science']\", review_count=2),\n",
       " Row(Title='Feather Stroke', authors=\"['Ramon Dharma Rajan']\", categories=\"['Fiction']\", review_count=2),\n",
       " Row(Title='Found II: More of the Best Lost, Tossed, and Forgotten Items from Around the World', authors=\"['Davy Rothbart']\", categories=\"['Humor']\", review_count=17),\n",
       " Row(Title='GRAFF: Most Fabulous Jewels In the World', authors=\"['Laurence Graff']\", categories=\"['Jewelry']\", review_count=1),\n",
       " Row(Title='Gay Blades', authors=' Missouri', categories='http://books.google.nl/books?id=-mtBTkn_gkkC&dq=Gay+Blades&hl=&cd=1&source=gbs_api', review_count=12),\n",
       " Row(Title='General Chemistry: Principles and Modern Applications (7th Edition)', authors=\"['Ralph H. Petrucci', 'William S. Harwood']\", categories=\"['Chemistry']\", review_count=27),\n",
       " Row(Title='Get Out Of My Mind', authors=\"['Sharon M. Draper']\", categories=\"['Juvenile Nonfiction']\", review_count=5),\n",
       " Row(Title='Gold and greenstone', authors=\"['Barry Crump']\", categories=\"['New Zealand fiction']\", review_count=1),\n",
       " Row(Title='Good Reasons with Contemporary Arguments: Reading, Designing, and Writing Effective Arguments, Second Edition', authors=\"['Eric Lupfer']\", categories=\"['English language']\", review_count=1),\n",
       " Row(Title='Grandfather, the King', authors=\"['Mar V. Puatu']\", categories=None, review_count=4),\n",
       " Row(Title='Great Movie Comedians: From Charlie Chaplin to Woody Allen.', authors=\"['Leonard Maltin']\", categories=\"['Comedians']\", review_count=2),\n",
       " Row(Title='Grey maiden, the story of a sword through the ages', authors=\"['Arthur D. Howden Smith']\", categories=None, review_count=1),\n",
       " Row(Title='Harry Potter und der Gefangene von Azkaban', authors=\"['J. K. Rowling']\", categories='\"[\"\"Children\\'s stories\"\"]\"', review_count=9),\n",
       " Row(Title='Have You Seen the Crocodile? (Reading Time)', authors=None, categories=None, review_count=1),\n",
       " Row(Title='Healthy Digestion the Natural Way: Preventing and Healing Heartburn, Constipation, Gas, Diarrhea, Inflammatory Bowel and Gallbladder Diseases, Ulcers, Irritable Bowel Syndrome, and More', authors=\"['Lindsey Berkson']\", categories=\"['Health & Fitness']\", review_count=26),\n",
       " Row(Title='Heverly', authors=\"['Neal F. Mears']\", categories=None, review_count=2),\n",
       " Row(Title='How to Design and Build Your Own House', authors=\"['Corie Richter']\", categories=\"['Architecture']\", review_count=13),\n",
       " Row(Title='Human Harvest : The Sacramento Murder Story', authors=None, categories=None, review_count=5),\n",
       " Row(Title=\"Hunneman's Amazing Fire Engines: Paul Revere's Apprentice Changed Firefighting in Colonial America (Fire Service History Series)\", authors=\"['Edward R. Tufts']\", categories=\"['History']\", review_count=3),\n",
       " Row(Title='Hunting The Hard Way', authors=\"['Howard Hill']\", categories=\"['Sports & Recreation']\", review_count=13),\n",
       " Row(Title='Hydrogen Sulfide in Production Operations (Oil and Gas Production)', authors=None, categories=None, review_count=1),\n",
       " Row(Title='If China Attacks Taiwan: Military Strategy, Politics and Economics (Asian Security Studies)', authors=\"['Steve Tsang']\", categories=\"['History']\", review_count=2),\n",
       " Row(Title=\"Jet Smarter: The Air Traveler's Rx\", authors=\"['Diana Fairechild']\", categories=\"['Health & Fitness']\", review_count=11),\n",
       " Row(Title='LA Cruz De San Andres: Premio Plameta 1994 (Fiction, Poetry & Drama)', authors=\"['Janet Pérez', 'Janet W. Pérez']\", categories=\"['Literary Criticism']\", review_count=1),\n",
       " Row(Title=\"Liberty's Women\", authors=\"['Cokie Roberts']\", categories=\"['History']\", review_count=1),\n",
       " Row(Title='Loss of the USS Thresher: Hearings Before the Joint Committee on Atomic Energy Congress of the United States Eighty-Eighth Congress First and Se', authors=\"['United States. Congress. Joint Committee on Atomic Energy']\", categories=\"['Governmental investigations']\", review_count=1),\n",
       " Row(Title='Love Handles for the Romantically Impaired', authors=' she again aims her insightful wit at the foibles of men and women in relationship', categories='Bethany House Pub', review_count=2),\n",
       " Row(Title='Manon Lescaut (Classics)', authors=\"['Antoine François Prévost', 'abbé Prévost', 'Germaine Greer']\", categories=\"['Fiction']\", review_count=5),\n",
       " Row(Title='Marry Me', authors=\"['John Updike']\", categories=\"['Fiction']\", review_count=12),\n",
       " Row(Title='Marvin Gaye, My Brother (Book)', authors=\"['Frankie Gaye']\", categories=\"['Biography & Autobiography']\", review_count=22),\n",
       " Row(Title='Minorities within Minorities: Equality, Rights and Diversity', authors=\"['Avigail I. Eisenberg', 'Jeff Spinner-Halev']\", categories=\"['Electronic books']\", review_count=1),\n",
       " Row(Title=\"More Than Meets The Eye: Fascinating Glimpses of God's Power and Design\", authors=\"['Richard A. Swenson']\", categories=\"['Religion']\", review_count=28),\n",
       " Row(Title='Natural Beauties', authors=\"['Adam Koons']\", categories=\"['Art']\", review_count=34),\n",
       " Row(Title=\"Necessary Steps: A Family's Journey: A family struggles with adolescent addiction\", authors=\"['Jane I. Barsumian']\", categories=\"['Self-Help']\", review_count=1),\n",
       " Row(Title='Nibbled: 200 Fabulous Finger Food Ideas', authors=\"['Sarah De Nardi']\", categories=\"['Appetizers']\", review_count=1),\n",
       " Row(Title=\"Other people's money\", authors=\"['John Kay']\", categories=\"['Business & Economics']\", review_count=1),\n",
       " Row(Title='PUSHKIN.Translated from the French by Nancy Amphoux.', authors=None, categories=None, review_count=2),\n",
       " Row(Title='Pack My Bag: A Self-Portrait', authors=\"['Henry Green']\", categories=None, review_count=2),\n",
       " Row(Title=\"Panda's New Toy: A Panda and Gander Story (Read Me)\", authors=\"['Joyce Dunbar']\", categories='\"[\"\"Children\\'s stories\"\"]\"', review_count=1),\n",
       " Row(Title='Panther Valley Tales', authors=\"['James Haldeman']\", categories=\"['Fiction']\", review_count=6),\n",
       " Row(Title='Paraguay', authors=\"['Peter Lambert', 'Andrew Nickson']\", categories=\"['History']\", review_count=4),\n",
       " Row(Title='Playboy June 1980 Playmate of the Year Dorthy Stratten Cover', authors=\"['Peter Bogdanovich']\", categories=\"['Motion picture actors and actresses']\", review_count=2),\n",
       " Row(Title='Preaching from the Types and Metaphors of the Bible (Kregel Reprint Library)', authors=\"['Benjamin Keach']\", categories=None, review_count=3),\n",
       " Row(Title='Program Evaluation and Performance Measurement: An Introduction to Practice', authors=\"['James C. McDavid', 'Irene Huse', 'Laura R. L. Hawthorn']\", categories=\"['Social Science']\", review_count=4),\n",
       " Row(Title='Promiscuous Unbound', authors=\"['Bex Brian']\", categories=\"['Fiction']\", review_count=1),\n",
       " Row(Title='Ricky Williams: Dreadlocks to Ditka', authors=\"['Steve Richardson']\", categories=\"['Sports & Recreation']\", review_count=1),\n",
       " Row(Title='Riding a Horse', authors=\"['Doug Payne']\", categories=\"['Sports & Recreation']\", review_count=1),\n",
       " Row(Title='Roadside History Of South Dakota', authors=\"['Linda M. Hasselstrom']\", categories=\"['History']\", review_count=1),\n",
       " Row(Title='Roy Lichtenstein,', authors=\"['Elizabeth Finch', 'Marshall N. Price', 'Graham Bader', 'Scott Manning Stevens']\", categories=\"['Art']\", review_count=4),\n",
       " Row(Title='Sadopaideia', authors=None, categories=None, review_count=8),\n",
       " Row(Title=\"Sophie and the Shofar: A New Year's Story\", authors=\"['Fran Manushkin']\", categories=\"['Juvenile Fiction']\", review_count=1),\n",
       " Row(Title='Spree Killers', authors=\"['Mark Safarik', 'Katherine Ramsland']\", categories=\"['Law']\", review_count=1),\n",
       " Row(Title='Suffer the Children', authors=' brutal', categories=' playing and laughing as before—but only when they feed. They hunger for blood…and they can’t get enough upon which to feast. Without it', review_count=50),\n",
       " Row(Title='Sufism & Good Character', authors=\"['Martin Lings']\", categories=\"['Sufism']\", review_count=3),\n",
       " Row(Title='Sulekha Select: The Indian Experience in a Connected World', authors=\"['Smart Information Worldwide', 'P. Nandy']\", categories=\"['Social Science']\", review_count=10),\n",
       " Row(Title='Tales of the Cthulhu Mythos Volume 2', authors=' and the oldest and strongest kind of fear is fear of the unknown.\"\" --H. P. LOVECRAFT', categories=' whose unspeakable denizens and monstrous landscapes--dread Cthulhu', review_count=3),\n",
       " Row(Title='Talking To Anxiety: Simple Ways to Support Someone in Your LIfe Who Suffers From Anxiety', authors=\"['Claudia J. Strauss', 'Jeanne Albronda Heaton']\", categories=\"['Self-Help']\", review_count=5),\n",
       " Row(Title=\"Target Blue: An insider's view of the N.Y.P.D\", authors=\"['Robert Daley']\", categories=None, review_count=3),\n",
       " Row(Title='The Bone is Pointed', authors=\"['Arthur W. Upfield']\", categories=\"['Fiction']\", review_count=19),\n",
       " Row(Title='The Bride from Odessa: Stories', authors=\"['Isaac Babel']\", categories=\"['Fiction']\", review_count=1),\n",
       " Row(Title='The Cat-Nappers', authors=\"['Pelham Grenville Wodehouse']\", categories=\"['Large type books']\", review_count=7),\n",
       " Row(Title='The Church of Christ: A Biblical Ecclesiology for Today', authors=\"['Everett Ferguson']\", categories=\"['Religion']\", review_count=4),\n",
       " Row(Title='The Complete Hiker, Revised and Expanded', authors=\"['Leonard M. Adkins']\", categories=\"['Sports & Recreation']\", review_count=1),\n",
       " Row(Title='The Confidential Clerk: A Play', authors='\"\" this is one of Eliot’s greatest comedies', categories='http://books.google.com/books?id=-TvYAgAAQBAJ&printsec=frontcover&dq=The+Confidential+Clerk:+A+Play&hl=&cd=1&source=gbs_api', review_count=2),\n",
       " Row(Title=\"The Construction of Nationhood: Ethnicity, Religion and Nationalism (1996 Wiles Lectures Given at the Queen's University of Belfa)\", authors=\"['Adrian Hastings', 'Professor of Theology (Emeritus) Adrian Hastings']\", categories=\"['History']\", review_count=2),\n",
       " Row(Title='The Contemporary Blacksmith', authors=\"['Dona Z. Meilach']\", categories=\"['Crafts & Hobbies']\", review_count=6),\n",
       " Row(Title='The Cosmic Decoy (Perry Rhodan #21)', authors=\"['K. H. Scheer', 'Wendayne Ackerman', 'F. J. Ackerman']\", categories=None, review_count=1),\n",
       " Row(Title='The Distant Hills (Lucy Walker her love stories, 3)', authors=\"['Lucy Walker']\", categories=\"['Large type books']\", review_count=1),\n",
       " Row(Title='The Handbook of Community Practice', authors=\"['Marie Weil', 'Michael S. Reisch', 'Mary L. Ohmer']\", categories=\"['Social Science']\", review_count=1),\n",
       " Row(Title='The Jaws Log, 30th Anniversary Edition', authors=\"['Carl Gottlieb']\", categories=\"['Performing Arts']\", review_count=10),\n",
       " Row(Title='The Law of Civilization and Decay: An Essay on History', authors=None, categories=None, review_count=1),\n",
       " Row(Title='The Man Who Lit the Stars', authors=' when the annoyingly beautiful daughter of said scam artist shows up at the door', categories='2017-04-17', review_count=3),\n",
       " Row(Title='The New American Apartment: Innovations in Residential Design and Construction: 30 Case Studies', authors=\"['Oscar Riera Ojeda']\", categories=\"['Architecture']\", review_count=3),\n",
       " Row(Title='The Notebooks of Captain Coignet: Soldier of the Empire, 1799-1816 (Greenhill Military Paperback)', authors=\"['Andrew Uffindell']\", categories=\"['History']\", review_count=5),\n",
       " Row(Title='The Old Man', authors=\"['Thomas Perry']\", categories=\"['Fiction']\", review_count=3),\n",
       " Row(Title='The Palace (The Adventures of Jecosan Tarres, Book 2)', authors=\"['Laura Lond']\", categories=\"['Fiction']\", review_count=13),\n",
       " Row(Title=\"The Repeal of Reticence: A History of America's Cultural and Legal Struggles over Free Speech, Obscenity, Sexual Liberation, and Modern Art\", authors=' sex educators', categories='Hill and Wang', review_count=2)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_required1.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a332198",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Only allow authors and categories that are either null or look like a list: ['Author1', 'Author2']\n",
    "list_like_pattern = r\"^\\[.*\\]$\"\n",
    "\n",
    "df_filtered = df_required1 \\\n",
    "    .filter(col(\"Title\").isNotNull() & col(\"review_count\").isNotNull()) \\\n",
    "    .filter(\n",
    "        (col(\"authors\").isNull() | col(\"authors\").rlike(list_like_pattern)) &\n",
    "        (col(\"categories\").isNull() | col(\"categories\").rlike(list_like_pattern))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6fdd813",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(Title='\"\"\"Carefree\"\" (R.K.O.Classic Screenplays)\"', authors=\"['Allan Scott', 'Ernest Pagano']\", categories=None, review_count=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b8cb524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "188980"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0632bc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#as the data size is small, we will be only saving itno 2 batches\n",
    "\n",
    "total_rows = df_filtered.count()\n",
    "batch_size = total_rows // 2\n",
    "batches = [\n",
    "    df_filtered.limit(batch_size),\n",
    "    df_filtered.subtract(df_filtered.limit(batch_size))\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61a0ff96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving content batch 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving content batch 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/21 15:13:04 WARN TransportChannelHandler: Exception in connection from /172.18.4.62:41361\n",
      "java.io.IOException: Connection timed out\n",
      "\tat sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)\n",
      "\tat sun.nio.ch.IOUtil.read(IOUtil.java:192)\n",
      "\tat sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:254)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    }
   ],
   "source": [
    "#storing in parquest agian\n",
    "\n",
    "for i, batch in enumerate(batches):\n",
    "    print(f\"Saving content batch {i + 1}...\")\n",
    "    batch.write.mode(\"overwrite\").parquet(f\"output/content/content_batch_{i + 1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b7db8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-project-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
